{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b45a34",
   "metadata": {},
   "source": [
    "#### 1. Pick one of the datasets from the ChatBot session(s) of the **TUT demo** (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e7091f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feel free to just use the following if you prefer...\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b2b4a",
   "metadata": {},
   "source": [
    "#### 2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a `pandas` DataFrame has, and then\n",
    "\n",
    "1. use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,  \n",
    "2. write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e7f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 391, Columns: 11\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print(f\"Rows: {rows}, Columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb96e7c",
   "metadata": {},
   "source": [
    "Observations are euqal to the amount of rows which represents individual instances or cases\n",
    "Variables are equal to the columns which represents measured characteristics or attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716dbcc",
   "metadata": {},
   "source": [
    "#### 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0b2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531db795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442c0420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Admiral    1\n",
       "Muffy      1\n",
       "Paula      1\n",
       "Patty      1\n",
       "Pate       1\n",
       "          ..\n",
       "Elvis      1\n",
       "Eloise     1\n",
       "Elmer      1\n",
       "Ellie      1\n",
       "Zucker     1\n",
       "Name: count, Length: 391, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21457ae4",
   "metadata": {},
   "source": [
    "#### 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe287ae",
   "metadata": {},
   "source": [
    "df.shape shows the total number of rows and columns in the dataset including both numeric and non-numeric variables, while df.describe() only shows numeric columns unless specified otherwise.\n",
    "The \"count\" in df.describe() reflects the number of non-missing values in numeric columns, not the total number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55072d6",
   "metadata": {},
   "source": [
    "#### 5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n",
    "\n",
    "- an \"attribute\", such as `df.shape` which does not end with `()`\n",
    "- and a \"method\", such as `df.describe()` which does end with `()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6879b5",
   "metadata": {},
   "source": [
    "an 'attribute' is an object that stores data or provides information about the object and it do not need parentheses when accessed. It will just simply returns a value.\n",
    "A 'method'is a function to perform an action or computation. It might modifying the object or returning new information when the method is called, and it requires parentheses as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca9829",
   "metadata": {},
   "source": [
    "#### 6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4972791",
   "metadata": {},
   "source": [
    "Count: The number of non-missing values in the column. If there are missing values, they are excluded from this count.\n",
    "\n",
    "Standard Deviation (std): A measure of the spread or dispersion of the non-missing values in the column.\n",
    "\n",
    "Minimum (min): The smallest non-missing value in the column.\n",
    "\n",
    "25th Percentile (25%): The value below which 25% of the non-missing data falls (also known as the first quartile).\n",
    "\n",
    "50th Percentile (50%): The median value of the non-missing data, where 50% of the values lie below and 50% lie above this point.\n",
    "\n",
    "75th Percentile (75%): The value below which 75% of the non-missing data falls (also known as the third quartile).\n",
    "\n",
    "Maximum (max): The largest non-missing value in the column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d373b",
   "metadata": {},
   "source": [
    "#### 7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15d7b1",
   "metadata": {},
   "source": [
    "1 \n",
    "When we are performing an analysis that requires accurate information for both Age and Weight, missing values in either column would lead to incomplete results.\n",
    "Using df.dropna() because we want to eliminate rows with missing data , but we do not want to remove entire columns like Age or Weight because they contain valuable information for other rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9743c11",
   "metadata": {},
   "source": [
    "2\n",
    "We are performing an analysis where the Weight column is irrelevant, and the column contains too many missing or unreliable values. In this case, it’s better to remove the entire column rather than trying to remove rows with missing val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9f22b",
   "metadata": {},
   "source": [
    "3 In this way, you can remove the unnecessary columns in order to ensure that df.dropna() only processes the columns that matter, making the data cleaning process more efficient and lead to a more focused and meaningful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc7d3b",
   "metadata": {},
   "source": [
    "4 First we use df.isna().sum() to find out the missing data and then we use df.dropna() to remove rows with any remaining missing values to ensure the analysis is complete and consistent and finally report the number of missing values before and after to help us understand the importance of data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a415c",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/e14bd61d-ace0-46e0-9559-f91be8ff0978"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45e229",
   "metadata": {},
   "source": [
    "Here's a summary of your session:\n",
    "\n",
    "Loading a Dataset: You loaded a dataset from a CSV file and explored basic properties like the number of rows and columns. You clarified the concepts of observations (rows) and variables (columns), where:\n",
    "\n",
    "Observations represent individual instances (rows) in your dataset.\n",
    "Variables represent characteristics or attributes (columns).\n",
    "Describing Data: You asked about summarizing columns in the dataset. The df.describe() method was introduced as a way to compute summary statistics (e.g., count, mean, min, max) for numeric columns by default. For non-numeric columns, df.describe(include=[object]) provides counts, unique values, and frequencies.\n",
    "\n",
    "Handling Missing Data:\n",
    "\n",
    "You explored the difference between using df.shape (an attribute that returns the dataset's dimensions) and df.describe() (a method that computes summary statistics).\n",
    "You learned how missing values (NaN) affect summary statistics. df.describe() excludes missing values in its calculations (affecting the \"count\" column), while df.shape still shows the full dimensions, including missing values.\n",
    "Comparison of df.dropna() vs. del df['col']:\n",
    "\n",
    "df.dropna(): You remove rows with missing data. This is useful when you need to retain the maximum number of columns and ensure your analysis is accurate.\n",
    "Example: Dropping rows with missing Weight values while keeping rows with valid data in other columns.\n",
    "del df['col']: You remove entire columns. This is helpful when a column is irrelevant or unreliable due to excessive missing data.\n",
    "Example: Deleting the Weight column because it has too many missing values but keeping rows to retain other information like Age and Height.\n",
    "Best Use Cases:\n",
    "\n",
    "You explored the preferred situations for using df.dropna() (when retaining columns with mostly complete data is more important than dropping some rows) versus del df['col'] (when a column is irrelevant or has too many missing values).\n",
    "This summarizes how we explored working with missing data and cleaning up the dataset by either removing rows or dropping irrelevant columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271cb71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count       mean        std    min      25%    50%       75%       max\n",
      "who                                                                          \n",
      "child   83.0  32.785795  33.466438  7.225  15.9000  26.25  32.19375  211.3375\n",
      "man    537.0  24.864182  44.021339  0.000   7.8542   9.50  26.38750  512.3292\n",
      "woman  271.0  46.570711  60.318995  6.750  10.5000  23.25  65.00000  512.3292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "grouped = df.groupby(\"who\")[\"fare\"].describe()\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9de86",
   "metadata": {},
   "source": [
    "2 Because 'count' records after removing the missing value, even if the missing value is not removed, this is the result of removing the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a87a9",
   "metadata": {},
   "source": [
    "The cause of The NameError is raised because Python does not recognize pd since pd is an alias for the pandas library, and the library has not been imported. To resolve this issue, we need to include the import statement for the pandas library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72cd8aa",
   "metadata": {},
   "source": [
    "The error occurs because titanics.csv does not exist at the specified URL and to fix it we should check if the URL and filename are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4d35b",
   "metadata": {},
   "source": [
    "The error occurs because DF is being used before it has been assigned any value and to fix it we just need to assign it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce926ea4",
   "metadata": {},
   "source": [
    "The error occurs because Python encounters an incomplete statement, to fix it, just add the another part of the parentheses up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9485b",
   "metadata": {},
   "source": [
    "The error occurs because group_by is not a valid pandas function, and describle is also not a valid pandas function. To fix it, we can just simply correct their name groupby and describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320948b",
   "metadata": {},
   "source": [
    "The error occurs because Sex does not exist in the DataFrame columns; the correct column name is sex. By fixing it, just type sex instead of Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba59ac",
   "metadata": {},
   "source": [
    "The NameError occurs because sex is not recognized as a string; instead, Python interprets it as a variable name, which has not been defined.To fix it, just add \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebbe46",
   "metadata": {},
   "source": [
    "After this exercises, I found Chatgpt is way more easier and faster than Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a60bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
